{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1089k  100 1089k    0     0   354k      0  0:00:03  0:00:03 --:--:--  354k\n"
     ]
    }
   ],
   "source": [
    "# Downloading tinyshakesphere for training\n",
    "!curl https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt > tinyshakespeare.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inspecting the tinyshakespeare text file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the text file\n",
    "with open('tinyshakespeare.txt','r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1115394 characters in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(text)} characters in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# Printing the first 1000 characters\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters (including white space): 65\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# Identifying the number of unique characters contained in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Number of unique characters (including white space): {vocab_size}{''.join(chars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic mapping between characters to integers\n",
    "\n",
    "More sophisticated examples include Google's SentencePiece and OpenAI's tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 46, 39, 49, 43, 57, 54, 43, 39, 56, 43, 1, 47, 52, 1, 42, 47, 45, 47, 58, 57]\n",
      "Shakespeare in digits\n"
     ]
    }
   ],
   "source": [
    "# Assigning numbers to each characters to encode the characters to integers\n",
    "ctoi = {char : num for num, char in enumerate(chars)}\n",
    "encode = lambda s: [ctoi[c] for c in s]\n",
    "print(encode('Shakespeare in digits'))\n",
    "\n",
    "# Reversely, decode integers back to characters\n",
    "itoc = {num : char for num, char in enumerate(chars)}\n",
    "decode = lambda l : ''.join([itoc[i] for i in l])\n",
    "print(decode(encode('Shakespeare in digits')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,) <dtype: 'int32'>\n",
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59], shape=(100,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the total text. Adapted the code to work with Tensorflow instead of pytorch\n",
    "import tensorflow as tf\n",
    "data = tf.convert_to_tensor(encode(text))\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data : 1003854\n",
      "Length of test data : 111540\n"
     ]
    }
   ],
   "source": [
    "# Train and validation split sets, with 9:1 ratio\n",
    "n = int(0.9*len(data))\n",
    "data_train = data[:n]\n",
    "data_test = data[n:]\n",
    "print(f'Length of train data : {len(data_train)}\\nLength of test data : {len(data_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([18 47 56 57 58  1 15 47 58], shape=(9,), dtype=int32)\n",
      "Input : [18], Output : 47\n",
      "Input : [18 47], Output : 56\n",
      "Input : [18 47 56], Output : 57\n",
      "Input : [18 47 56 57], Output : 58\n",
      "Input : [18 47 56 57 58], Output : 1\n",
      "Input : [18 47 56 57 58  1], Output : 15\n",
      "Input : [18 47 56 57 58  1 15], Output : 47\n",
      "Input : [18 47 56 57 58  1 15 47], Output : 58\n"
     ]
    }
   ],
   "source": [
    "# Starting with block_size implementation\n",
    "block_size = 8\n",
    "print(data_train[:block_size + 1])\n",
    "x = data_train[:block_size]\n",
    "y = data_train[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'Input : {context}, Output : {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1 51 63  1 41 53 39 58]\n",
      " [39 42  0 20 47 57  1 52]\n",
      " [32 53  1 56 43 60 43 50]\n",
      " [54 39 52 63  1 54 47 43]], shape=(4, 8), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[51 63  1 41 53 39 58  6]\n",
      " [42  0 20 47 57  1 52 39]\n",
      " [53  1 56 43 60 43 50  1]\n",
      " [39 52 63  1 54 47 43 41]], shape=(4, 8), dtype=int32)\n",
      "When input is [1] the target is 51\n",
      "When input is [1, 51] the target is 63\n",
      "When input is [1, 51, 63] the target is 1\n",
      "When input is [1, 51, 63, 1] the target is 41\n",
      "When input is [1, 51, 63, 1, 41] the target is 53\n",
      "When input is [1, 51, 63, 1, 41, 53] the target is 39\n",
      "When input is [1, 51, 63, 1, 41, 53, 39] the target is 58\n",
      "When input is [1, 51, 63, 1, 41, 53, 39, 58] the target is 6\n",
      "When input is [39] the target is 42\n",
      "When input is [39, 42] the target is 0\n",
      "When input is [39, 42, 0] the target is 20\n",
      "When input is [39, 42, 0, 20] the target is 47\n",
      "When input is [39, 42, 0, 20, 47] the target is 57\n",
      "When input is [39, 42, 0, 20, 47, 57] the target is 1\n",
      "When input is [39, 42, 0, 20, 47, 57, 1] the target is 52\n",
      "When input is [39, 42, 0, 20, 47, 57, 1, 52] the target is 39\n",
      "When input is [32] the target is 53\n",
      "When input is [32, 53] the target is 1\n",
      "When input is [32, 53, 1] the target is 56\n",
      "When input is [32, 53, 1, 56] the target is 43\n",
      "When input is [32, 53, 1, 56, 43] the target is 60\n",
      "When input is [32, 53, 1, 56, 43, 60] the target is 43\n",
      "When input is [32, 53, 1, 56, 43, 60, 43] the target is 50\n",
      "When input is [32, 53, 1, 56, 43, 60, 43, 50] the target is 1\n",
      "When input is [54] the target is 39\n",
      "When input is [54, 39] the target is 52\n",
      "When input is [54, 39, 52] the target is 63\n",
      "When input is [54, 39, 52, 63] the target is 1\n",
      "When input is [54, 39, 52, 63, 1] the target is 54\n",
      "When input is [54, 39, 52, 63, 1, 54] the target is 47\n",
      "When input is [54, 39, 52, 63, 1, 54, 47] the target is 43\n",
      "When input is [54, 39, 52, 63, 1, 54, 47, 43] the target is 41\n"
     ]
    }
   ],
   "source": [
    "## To be worked on : packaging the code with script with variables for later\n",
    "# Depiction of the chunk(or in here, block)-wise transformation.\n",
    "# Having varied blocksize allows the algorithm to take into account the context for inference purpose\n",
    "\n",
    "\n",
    "\n",
    "tf.random.set_seed(1337) # To be sure to have consistent random number\n",
    "batch_size = 4 # The number of independent sequences to train in parallel\n",
    "block_size = 8 # The maximum context length for prediction\n",
    "\n",
    "def get_batch(split):\n",
    "    data = data_train if split == 'train' else data_test\n",
    "    # Retrieving batches randomly\n",
    "    ix = tf.random.uniform(shape = (batch_size,),\n",
    "                           maxval = len(data) - block_size,\n",
    "                           dtype = tf.int32)\n",
    "    # Stacking the list of tensors\n",
    "    x = tf.stack([data[i:i+block_size] for i in ix])\n",
    "    y = tf.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(xb)\n",
    "print(yb)\n",
    "for batch in range(batch_size):\n",
    "    for block in range(block_size):\n",
    "        context = xb[batch, :block+1]\n",
    "        target = yb[batch, block]\n",
    "        print(f'When input is {context.numpy().tolist()} the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 200\n",
    "\n",
    "# A function to average up the loss in multiple batches for both splits\n",
    "# @tf.function : removing the code, despite slower performance as it causes an error\n",
    "def estimate_loss():\n",
    "    output = {}\n",
    "    model.trainable = False # Setting the model to evaluation phase\n",
    "    for split in ['train','val']:\n",
    "        losses = []\n",
    "        for _ in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model.call(X,Y)\n",
    "            losses.append(loss)\n",
    "        output[split] = tf.reduce_mean(losses)\n",
    "    model.trainable = True # Setting the model back to training phase\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 65)\n",
      "4.1691484\n",
      "\n",
      "sZTe-Wz-K-?hNk?Yr:r'KUFLHH:QlLbpCkI\n",
      "oYwnqdPrE\n",
      "!zgz'T:,?ZgzxEjHtfpzAQjGjM&vv.;OBdqFlQ qxcwcewWhPKs:$'\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        '''Initializing embedding layer, which maps integer indices to\n",
    "        dense vectors of vocab size'''\n",
    "        super(BigramLanguageModel, self).__init__()\n",
    "        self.token_embedding_table = tf.keras.layers.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def call(self, idx, targets=None):\n",
    "        '''Method for loss calculation, based on idx (input token indices) and\n",
    "        target (target token indices)\n",
    "        B : Batch size\n",
    "        T : Time = sequence length = block size\n",
    "        C : Channel = number of classes = vocab size\n",
    "        '''\n",
    "        logits = self.token_embedding_table(idx)  # Replacing embedding to the indices\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Reshaping the tensor so that it's compatible with categorical cross entropy\n",
    "            B, T, C = tf.shape(logits) # Get the shape of logits\n",
    "            logits = tf.reshape(logits, (B * T, C)) # Flatten logits for comparison\n",
    "            targets = tf.reshape(targets, (B * T,)) # Flatten targets\n",
    "            loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(targets, logits, from_logits=True))\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        '''\n",
    "        Text generating method\n",
    "        '''\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = tf.nn.softmax(logits, axis=-1)  # (B, C)\n",
    "            # sample prediction from the distribution\n",
    "            idx_next = tf.random.categorical(tf.math.log(probs), num_samples=1, dtype=tf.int64)\n",
    "\n",
    "#            idx_next = tf.random.categorical(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = tf.concat([idx, tf.cast(idx_next, tf.int32)], axis=1)  # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model.call(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss.numpy())\n",
    "\n",
    "print(decode(model.generate(idx=tf.zeros((1, 1), dtype=tf.int32), max_new_tokens=100)[0].numpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;241m4000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m eval_iters \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Sample a batch of data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [16], line 11\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eval_iters):\n\u001b[0;32m---> 11\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcall(X,Y)\n\u001b[1;32m     13\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[0;32mIn [15], line 18\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     14\u001b[0m ix \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(shape \u001b[38;5;241m=\u001b[39m (batch_size,),\n\u001b[1;32m     15\u001b[0m                        maxval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m block_size,\n\u001b[1;32m     16\u001b[0m                        dtype \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Stacking the list of tensors\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack([data[i:i\u001b[38;5;241m+\u001b[39mblock_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack([data[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:i\u001b[38;5;241m+\u001b[39mblock_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "Cell \u001b[0;32mIn [15], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m ix \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(shape \u001b[38;5;241m=\u001b[39m (batch_size,),\n\u001b[1;32m     15\u001b[0m                        maxval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m block_size,\n\u001b[1;32m     16\u001b[0m                        dtype \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Stacking the list of tensors\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack([\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack([data[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:i\u001b[38;5;241m+\u001b[39mblock_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/tensor_getitem_override.py:230\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m begin:\n\u001b[1;32m    228\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m    229\u001b[0m   packed_begin, packed_end, packed_strides \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 230\u001b[0m       \u001b[43marray_ops_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    231\u001b[0m       array_ops_stack\u001b[38;5;241m.\u001b[39mstack(end),\n\u001b[1;32m    232\u001b[0m       array_ops_stack\u001b[38;5;241m.\u001b[39mstack(strides))\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;66;03m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[39;00m\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;66;03m# same dtypes.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (packed_begin\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    236\u001b[0m       packed_end\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    237\u001b[0m       packed_strides\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64):\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/array_ops_stack.py:74\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     72\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# If the input is a constant list, it can be converted to a constant op\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Input list contains non-constant tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1305\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m inferred_dtype:\n\u001b[1;32m   1304\u001b[0m   v \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(_cast_nested_seqs_to_dtype(dtype), v)\n\u001b[0;32m-> 1305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_autopacking_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpacked\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1212\u001b[0m, in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m   1209\u001b[0m   \u001b[38;5;66;03m# NOTE: Fast path when all the items are tensors, this doesn't do any type\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m   \u001b[38;5;66;03m# checking.\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(elem, core\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m list_or_tuple):\n\u001b[0;32m-> 1212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_or_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m must_pack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m converted_elems \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:6714\u001b[0m, in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   6713\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6714\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6715\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maxis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   6717\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for step in tf.range(4000):\n",
    "    if step % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # Evaluate the loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits, loss = model(xb,yb)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "print(f'Final Loss: {loss.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kv$kqwUpC?urj3\n",
      ";XhpzNaZoaY&NH,qr&pbDL-,Wj,aj C'vo:ue?HpEuxkvzuX&eW\n",
      ",XdwB!tPK,Qg'SDIDPp?,lotv'AH t;u$f;OpdPrBur,rMRNf-EA.HRtuwpebAk\n",
      "zkTxFvo,$.CwM;G!XpLU!fbW$GldJJQgm ggRGdaYcDBUQx3sJSQ3Z;O IIYWeDm$zXIQSSyW&kjDy-u$s\n",
      "dFFulXTXn?Lj\n",
      "Dmsp.Su'kP'\n",
      "Cc,E,pE'v,Vwide!jG;Z$PlByDYj:jhJKpUmYYvV-qAdIZjNMqOBN&mb;gpDxbnNlEXIYWj'IOFBtSav-ESKCbuad.cF:qu';!S&M Wya\n",
      "hVs:HDPVNpRsW3m!bzpT3sW&HP&?tibkmsxfxObE$3rd\n",
      "zyoPUSBEp'LXubU.$U:VSz-Aw\n",
      ":3C j:&aqUEQIJZyRDSLbP.EN.bLBUIUXg:RROiemtJg!m3WSmUIMIXq-nVMHo?$y'K-hcOO& jkIP-ww,ee?OxwsfsuXJErdmxEvYWQ3h!NjO!GZTuMVss!udMKw-.IHjXe?'lqRf?:gSY\n",
      ":rwqMJ!UkklxEeXXjRZ 3 'xhP,HrQ!QfRtdnR\n",
      "xbnsuKJsIZF\n",
      "V\n",
      "lpZ-\n",
      "HRqQiLPRtvEEFiXHC?ghkn$ODErqDcffgDpw&-wCj-cHuEVS'k?3ViJD'ct,NuUjtWn-cw\n",
      "aAvPyidTAyyeRZ!e:odF.uN CYRxYTcN.&Qibd. BGcx3fTIxfoBPKSWVSf,AWtL$RNkfgx ;san?s;vxIzwfKw&'sl:SBvqTWIzg:FFJUHwlx\n",
      "VSQs,GmAM:qrSH?bUzu dLzXfSCz$gyE'Ncy;lpeAYHQSf&'l??,TNX'Fvv,h3?:qp\n",
      " x\n",
      "U,FWSOt,rSyno3P'qgqiGViwj:phjs.CuW3SMjdiKUb!3'Pqz,WwG3whB;m-bVsUBxHLtJHcU;qSnLcy.Qf3gCijyEtE.tzwePei&VJ!GlJ'mHH-q,UI,3vToVWANIs?Y;\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequence\n",
    "idx = tf.zeros((1, 1), dtype=tf.int32)\n",
    "generated_sequence = model.generate(idx, max_new_tokens=1000).numpy()\n",
    "print(decode(generated_sequence[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mathematical trick self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens learning from previous context, calculating average of all to previous tokens\n",
    "B,T,C = 4,8,2\n",
    "x = tf.random.uniform(shape=(B, T,C))\n",
    "\n",
    "xbow = tf.zeros((B,T,C)) # Defining a bag of words\n",
    "for b in range (B):\n",
    "    for t in range (T):\n",
    "        xprev = x[b, :t+1] # Batch, including the tth token\n",
    "        xbow = xbow.numpy()  # Convert xbow to numpy array to support assignment\n",
    "        xbow[b, t] = tf.reduce_mean(xprev, axis=0).numpy()  # Calculate mean and assign to xbow\n",
    "        xbow = tf.convert_to_tensor(xbow)  # Convert back to tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.linalg.band_part(tf.ones((T,T)),num_lower = 8, num_upper= 0) # Calculating weights with matrix\n",
    "w = w / tf.math.reduce_sum(w, axis = 1, keepdims = True)\n",
    "\n",
    "xbow2 = w @ x\n",
    "tf.experimental.numpy.allclose(xbow,xbow2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = tf.linalg.band_part(tf.ones((T,T)),num_lower = 8, num_upper= 0)\n",
    "w = tf.zeros((T,T))\n",
    "w = tf.where(tril == 0, float('-inf'), w) # Indicating future bow cannot communicate with the past\n",
    "w = tf.nn.softmax(w, axis = -1) # normalizing the weight matrix\n",
    "xbow3 = w @ x\n",
    "tf.experimental.numpy.allclose(xbow,xbow3).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BigramLanguageModel' object has no attribute 'position_embedding_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[1;32m     55\u001b[0m model \u001b[38;5;241m=\u001b[39m BigramLanguageModel(vocab_size)\n\u001b[0;32m---> 56\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn [25], line 21\u001b[0m, in \u001b[0;36mBigramLanguageModel.call\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m'''Method for loss calculation, based on idx (input token indices) and\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mtarget (target token indices)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mB : Batch size\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mT : Time = sequence length = block size\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mC : Channel = number of classes = vocab size\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     20\u001b[0m token_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(idx)  \u001b[38;5;66;03m# Replacing embedding to the indices\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embedding_table\u001b[49m(tf\u001b[38;5;241m.\u001b[39mrange(T, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m token_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x  ) \u001b[38;5;66;03m# (B, T, vocab_size)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BigramLanguageModel' object has no attribute 'position_embedding_table'"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1337)\n",
    "n_embed = 32\n",
    "\n",
    "class BigramLanguageModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        '''Initializing embedding layer, which maps integer indices to\n",
    "        dense vectors of vocab size'''\n",
    "        super(BigramLanguageModel, self).__init__()\n",
    "        self.token_embedding_table = tf.keras.layers.Embedding(vocab_size, n_embed)\n",
    "        self.lm_head = tf.keras.layers.Dense(units=vocab_size)\n",
    "\n",
    "    def call(self, idx, targets=None):\n",
    "        '''Method for loss calculation, based on idx (input token indices) and\n",
    "        target (target token indices)\n",
    "        B : Batch size\n",
    "        T : Time = sequence length = block size\n",
    "        C : Channel = number of classes = vocab size\n",
    "        '''\n",
    "        token_emb = self.token_embedding_table(idx)  # Replacing embedding to the indices\n",
    "        pos_emb = self.position_embedding_table(tf.range(T, dtype=tf.int32)) # (T,C)\n",
    "        x = token_emb + pos_emb # (B,T,C)\n",
    "        logits = self.lm_head(x  ) # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Reshaping the tensor so that it's compatible with categorical cross entropy\n",
    "            B, T, C = tf.shape(logits) # Get the shape of logits\n",
    "            logits = tf.reshape(logits, (B * T, C)) # Flatten logits for comparison\n",
    "            targets = tf.reshape(targets, (B * T,)) # Flatten targets\n",
    "            loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(targets, logits, from_logits=True))\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        '''\n",
    "        Text generating method\n",
    "        '''\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = tf.nn.softmax(logits, axis=-1)  # (B, C)\n",
    "            # sample prediction from the distribution\n",
    "            idx_next = tf.random.categorical(tf.math.log(probs), num_samples=1, dtype=tf.int64)\n",
    "\n",
    "#            idx_next = tf.random.categorical(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = tf.concat([idx, tf.cast(idx_next, tf.int32)], axis=1)  # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model.call(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss.numpy())\n",
    "\n",
    "print(decode(model.generate(idx=tf.zeros((1, 1), dtype=tf.int32), max_new_tokens=100)[0].numpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 8, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Video from 1:00:00. Need to recheck how self-attention functions\n",
    "\n",
    "# Version 4: self-attention\n",
    "tf.random.set_seed(1337)\n",
    "B,T,C = 4, 8, 32 # batch, time, channels\n",
    "x = tf.random.normal(shape=(B, T, C))\n",
    "\n",
    "# Single head perform self-attention\n",
    "head_size = 16\n",
    "key = tf.keras.layers.Dense(units=head_size, use_bias=False)\n",
    "query = tf.keras.layers.Dense(units=head_size, use_bias=False)\n",
    "value = tf.keras.layers.Dense(units=head_size, use_bias=False)\n",
    "\n",
    "# All tokens in all positions produce independent key and query\n",
    "k = key(x) # B, T, 16\n",
    "q = query(x) # B, T, 16\n",
    "# Communicating key with query\n",
    "w = q @ tf.transpose(k, perm=[0,2,1]) # (B, T, 16) @ (B, 16, T) -> (B,T,T)\n",
    "\n",
    "tril = tf.linalg.band_part(tf.ones((T,T)),num_lower = 8, num_upper= 0)\n",
    "w = tf.zeros((T,T))\n",
    "w = tf.where(tril == 0, float('-inf'), w) # Upper triangular masking, indicating future bow cannot communicate with the past\n",
    "w = tf.nn.softmax(w, axis = -1) # normalizing the weight matrix\n",
    "\n",
    "v = value(x)\n",
    "out = w @ v\n",
    "#out = w @ x # K : private information\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.5      0.5      0.       0.       0.       0.       0.       0.      ]\n",
      " [0.333333 0.333333 0.333333 0.       0.       0.       0.       0.      ]\n",
      " [0.25     0.25     0.25     0.25     0.       0.       0.       0.      ]\n",
      " [0.2      0.2      0.2      0.2      0.2      0.       0.       0.      ]\n",
      " [0.166667 0.166667 0.166667 0.166667 0.166667 0.166667 0.       0.      ]\n",
      " [0.142857 0.142857 0.142857 0.142857 0.142857 0.142857 0.142857 0.      ]\n",
      " [0.125    0.125    0.125    0.125    0.125    0.125    0.125    0.125   ]]\n"
     ]
    }
   ],
   "source": [
    "# Verifying whether the row sum of weights equal 1\n",
    "import numpy as np\n",
    "# Convert TensorFlow tensor to NumPy array\n",
    "w_np = w.numpy()\n",
    "\n",
    "# Set NumPy print options to suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Print the tensor\n",
    "print(w_np.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens\n",
    "- Each example across batch dimension is of course processed completely independently and never 'talk' to each other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
